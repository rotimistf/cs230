{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2fb7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow.keras.layers as tfl  \n",
    "from tensorflow.python.framework import ops \n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddfff89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c78cdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize an array\n",
    "def fn_normalize_col(x):\n",
    "    if x.dtype == 'object' :\n",
    "        return x\n",
    "    return (x - np.mean(x))/np.std(x)\n",
    "\n",
    "#Convert array to tensor and specify shape\n",
    "def fn_target_to_tensor(data) :\n",
    "    return tf.reshape(tf.convert_to_tensor(data),[data.shape[0],1])\n",
    "\n",
    "#Split data into training and test sets using a defined probability\n",
    "def fn_split_data(X,Y, train_prob = 0.8, seed = 0) : \n",
    "    \n",
    "    X_train = X.sample(frac=train_prob, random_state=seed) \n",
    "    X_test   = X.drop(X_train.index) \n",
    "    Y_train = Y.loc[X_train.index] \n",
    "    Y_test = Y.drop(X_train.index) \n",
    "    \n",
    "    X_train=tf.convert_to_tensor(X_train) \n",
    "    X_test=tf.convert_to_tensor(X_test)\n",
    "\n",
    "    Y_train=fn_target_to_tensor(Y_train) \n",
    "    Y_test=fn_target_to_tensor(Y_test) \n",
    "    \n",
    "    return [X_train,X_test,Y_train,Y_test] \n",
    " \n",
    "#Get and normalize data\n",
    "def fn_get_coral_data(cols_X, cols_Y, cols_norm, train_prob = 0.9, seed = 0) : \n",
    "    \n",
    "    data = pd.read_csv(\n",
    "    \"data//coral_total_cover.csv\",header=0).dropna()\n",
    "    \n",
    "    X = data.copy().filter(cols_X)\n",
    "    Y = data.copy().filter(cols_Y)\n",
    "   \n",
    "    Y = (Y > 8) * 1 \n",
    "    X[[\"o_ocean\"]] = (X[[\"o_ocean\"]] == \"CARIB\" ) * 1\n",
    "    \n",
    "    X = X.apply(fn_normalize_col,axis=0)\n",
    "    \n",
    "    return fn_split_data(X,Y, train_prob, seed) \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af93ec7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create hyperband tunable model\n",
    "def tunable_model(hp) :\n",
    "    \n",
    "    hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "    hp_l_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    \n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.Input(shape=(11,)))\n",
    "    model.add(tfl.Dense(hp_units, activation='relu'))  \n",
    "    model.add(tfl.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_l_rate),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "               metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy'),  tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall'),])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38bb192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f55f244",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get training and test data\n",
    "col_Y =  [\"o_coral_cover\"]\n",
    "cols_X = [\"o_ocean\", \"o_lat\", \"o_long\", \"o_depth\",\n",
    "           \"o_human_pop50\", \"o_land_area50\", \"o_storm_30yr\",\"o_l_att_mean\", \"o_npp_mean\", \"o_sst_mean\", \"o_wave_mean\"]\n",
    "\n",
    "\n",
    "cols_geo = [\"o_ocean\",\"o_lat\", \"o_long\"]\n",
    "\n",
    "\n",
    "cols_env = [\"o_depth\", \"o_storm_30yr\",\"o_l_att_mean\", \"o_npp_mean\", \"o_sst_mean\", \"o_wave_mean\"]\n",
    "\n",
    "\n",
    "cols_human = [\"o_human_pop50\", \"o_land_area50\"]\n",
    "\n",
    "    \n",
    "cols_sd  = [\"o_lat\", \"o_long\", \"o_depth\",\n",
    "           \"o_human_pop50\", \"o_land_area50\", \"o_storm_30yr\",\"o_l_att_mean\", \"o_npp_mean\", \"o_sst_mean\", \"o_wave_mean\"] \n",
    "\n",
    "input_size = len(cols_X)\n",
    "\n",
    "X_train,X_test, Y_train,Y_test = fn_get_coral_data(cols_X,col_Y,cols_sd,train_prob=0.9, seed=230) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fba5db0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ead4300",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configure Tuner\n",
    "\n",
    "tuner = kt.Hyperband(tunable_model,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=1000,\n",
    "                     project_name='deepreef_SE',\n",
    "                     factor=3)\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a252abbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the optimal hyperparameters\n",
    "tuner.search(X_train, Y_train, epochs=300, validation_split=0.1, callbacks=[stop_early])\n",
    "\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=10)[0]\n",
    "\n",
    "print(f\"\"\"optimal number of units is {best_hps.get('units')} and the optimal learning rate is {best_hps.get('learning_rate')}.\n",
    "\"\"\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a68dc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find Optimal Epochs\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X_train, Y_train, epochs=300, validation_split=0.1)\n",
    "\n",
    "val_prec_per_epoch = np.array(history.history['val_precision'])\n",
    "val_recall_per_epoch = np.array(history.history['val_recall'])\n",
    "\n",
    "val_f1_per_epoch = (2 * ((val_prec_per_epoch * val_recall_per_epoch)/(val_prec_per_epoch + val_recall_per_epoch))).tolist()\n",
    "best_epoch = val_f1_per_epoch.index(max(val_f1_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0f0b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc92196",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get hyperband tuned model\n",
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Train the model until best epoch\n",
    "hypermodel.fit(X_train, Y_train, epochs=best_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ccac91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate Test Set\n",
    "\n",
    "eval_result = hypermodel.evaluate(X_test, Y_test)\n",
    "print(\"[test loss, test accuracy, test f1]:\", eval_result[0],  eval_result[1], 2*((eval_result[2]*eval_result[3])/(eval_result[2]+eval_result[3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc3c7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute absolute mean of the input weights\n",
    "abs(np.apply_along_axis(np.mean, 1,hypermodel.layers[0].get_weights()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af03ef1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d50980c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
